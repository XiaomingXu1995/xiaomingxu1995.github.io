<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <title>Notes</title>
</head>
<body>

  <!-- 一级标题 -->
  <h1>积跬步，至千里</h1>
  <p>静下心，去做事</p>

  <!-- 二级标题 -->
  <h2>Contents</h2>
  <ul>
    <li><a href="#attention">Attention</a></li>
    <ul>
      <li><a href="#attention-mla">MLA</a></li>
      <li><a href="#sparse-attention">Sparse Attention</a></li>
    </ul>
    <li><a href="#cuda_notes">CUDA Notes</a></li>
    <li><a href="#low-bit">Low Bit training</a></li>
    <ul>
      <li><a href="#low-bit-paper">Low bit paper</a></li>
      <li><a href="#low-bit-contents">Low Bit contents</a></li>

    </ul>
    <li><a href="#technique">Technique</a></li>
    <ul>
      <li><a href="#docker">Docker</a></li>
      <li><a href="#network">Network</a></li>
    </ul>
  </ul>

  <!-- 内容部分 -->
  <h2 id="attention">Attention</h2>
  <h3 id="attention-mla">MLA</h3>
  <ul>
    <li><span style="color: gray" size="6px">[2025.08.02]</span>
      <a href="https://zhuanlan.zhihu.com/p/19585986234" target="_blank">再读MLA，还有多少细节是你不知道的</a>
    </li>
    <li><span style="color: gray" size="6px">[2025.08.04]</span>
      <a href="https://zhuanlan.zhihu.com/p/16730036197" target="_blank">deepseek技术解读(1)-彻底理解MLA（Multi-Head Latent Attention）</a>
    </li>
    <li><span style="color: gray" size="6px">[2025.08.04]</span>
      <a href="https://www.bilibili.com/video/BV1F1421B7iv" target="_blank">旋转位置编码RoPE</a>
    </li>
    <li><span style="color: gray" size="6px">[2025.08.04]</span>
      <a href="https://zhuanlan.zhihu.com/p/662498827" target="_blank">大模型推理加速：看图学KV Cache</a>
    </li>
  </ul>

  <h3 id="sparse-attention">Sparse Attention</h3>
  <ul>
    <li><span style="color: gray" size="6px">[2025.08.05]</span>
      <a href="https://www.bilibili.com/video/BV1YXAsesEAJ" target="_blank">全网首发！ DeepSeekNSA:Native Sparse Attention 最通俗讲解</a>
    </li>
    <li><span style="color: gray" size="6px">[2025.08.05]</span>
      <a href="https://arxiv.org/pdf/2502.11089" target="_blank">[paper] Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention</a>
    </li>
    <li><span style="color: gray" size="6px">[2025.08.05]</span>
      <a href="https://arxiv.org/pdf/2502.13189" target="_blank">[paper] MOBA: Mixture of Block Attention for Long-context LLMs</a>
    </li>
    <li><span style="color: gray" size="6px">[2025.08.05]</span>
      <a href="https://zhuanlan.zhihu.com/p/24774848974" target="_blank">笔记：MoBA 与 Native Sparse Attention</a>
    </li>
  </ul>


  <h2 id="cuda_notes">CUDA Notes</h2>
  <p>Notes of cuda</p>
  <ul>
    <li><span style="color: gray" size="6px">[2025.07.20]</span>
      <a href="https://zhuanlan.zhihu.com/p/4746910252" target="_blank">CUDA shared memory避免bank conflict的swizzling机制解析</a>
    </li>
    <li><span style="color: gray" size="6px">[2025.07.24]</span>
      <a href="https://chatgpt.com/c/6881afe8-9a30-8331-b2e2-036122731a23" target="_blank">Swizzling for bank conflict的交流理解</a>
    </li>
    <li><span style="color: gray" size="6px">[2025.07.27]</span>
      <a href="https://zhuanlan.zhihu.com/p/697228676" target="_blank">ldmatrix指令的详细解释</a>
    </li>
  </ul>


  <h2 id="low-bit">Low Bit training</h2>
  <p></p>
  <h3 id="low-bit-paper">paper</h3>
  <ul>
    <li><span style="color: gray" size="6px">[2025.07.21]</span>
      <a href="https://arxiv.org/abs/2410.19313" target="_blank">COAT: Compressing Optimizer states and Activation for Memory-Efficient FP8 Training</a>
    </li>
    <li><span style="color: gray" size="6px">[2025.07.22]</span>
      <a href="https://arxiv.org/abs/2309.01507" target="_blank">Memory Efficient Optimizers with 4-bit States</a>
    </li>
  </ul>

  <h3 id="low-bit-contents">Contents</h3>
  <ul>
    <li><span style="color: gray" size="6px">[2025.07.26]</span>
      <a href="https://chatgpt.com/c/68843f2b-d86c-832b-8ef1-7c3488614b60" target="_blank">混合精度训练流程以及master weight</a>
    </li>
  </ul>

  <h2 id="technique">Technique</h2>
  <p></p>
  <h3 id="docker">Docker</h3>
  <ul>
    <li><span style="color: gray" size="6px">[2025.07.21]</span>
      <a href="https://chatgpt.com/c/68771c87-5a2c-8002-83d5-3f0c95fc3227" target="_blank">Docker 相关命令</a>
    </li>
  </ul>
  
  <h3 id="network">Network</h3>
  <ul>
    <li><span style="color: gray" size="6px">[2025.07.22]</span>
      <a href="https://chatgpt.com/c/687efc17-40e8-832a-b133-1abfa72e853f" target="_blank">Macbook Wi-Fi不能上网</a>
    </li>
    <li><span style="color: gray" size="6px">[2025.07.22]</span>
      <a target="_blank">Orin 配置k8s</a>
    </li>
  </ul> 

  <h3 id="git">Git</h3>
  <ul>
    <li><span style="color: gray" size="6px">[2025.07.22]</span>
      <a href="https://chatgpt.com/c/688b2d9a-a83c-832e-9f27-2f35320c8eb8">Git check PR before merge</a>
    </li>

  </ul>


  

</body>
</html>
